{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01dbcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a1e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter CCR Link: https://results.eci.gov.in/PcResultGenJune2024/candidateswise-S0112.htm\n",
      "Data extracted and saved to CCR_Andhra Pradesh_Vijayawada.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the URL\n",
    "url = input(\"Enter CCR Link: \")\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract state and parliamentary constituency name\n",
    "header = soup.find(\"div\", class_=\"page-title\")\n",
    "if header:\n",
    "    h2_tag = header.find(\"h2\")\n",
    "    if h2_tag:\n",
    "        # Extract text from the span and strong tags within the h2 tag\n",
    "        span_tag = h2_tag.find(\"span\")\n",
    "        strong_tag = h2_tag.find(\"strong\")\n",
    "        \n",
    "        if span_tag and strong_tag:\n",
    "            # Get the raw text of pc_name and state\n",
    "            pc_name_raw = span_tag.get_text(strip=True).strip()\n",
    "            state = strong_tag.get_text(strip=True).strip('()')\n",
    "            \n",
    "            # Remove leading numeric characters, hyphens, and state information from pc_name\n",
    "            pc_name = pc_name_raw.split('-')[1].split('(')[0].strip()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Could not find the span or strong tag with state and pc_name information\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not find the h2 tag with state and pc_name information\")\n",
    "else:\n",
    "    raise ValueError(\"Could not find the header with state and pc_name\")\n",
    "\n",
    "# Initialize lists to store candidate details\n",
    "candidates = []\n",
    "\n",
    "# Extract candidate details from the table\n",
    "table = soup.find('div', class_='row')\n",
    "candidate_divs = table.find_all('div', class_='col-md-4 col-12')\n",
    "\n",
    "for candidate_div in candidate_divs:\n",
    "    # Extract candidate's image URL\n",
    "    img_tag = candidate_div.find('img')\n",
    "    img_url = img_tag['src'] if img_tag else ''\n",
    "\n",
    "    # Extract candidate's status (won/lost) and votes\n",
    "    status_div = candidate_div.find('div', class_='status')\n",
    "    status = status_div.find('div').text.strip()\n",
    "    votes_info = status_div.find_all('div')[1].text.strip()\n",
    "    total_votes, margin = '', ''\n",
    "    \n",
    "    # Handle cases where votes_info doesn't split into two parts\n",
    "    if '(' in votes_info and ')' in votes_info:\n",
    "        total_votes = votes_info.split('(')[0].strip().replace(',', '')\n",
    "        margin = votes_info.split('(')[1].split(')')[0].strip().replace('+', '').replace('-', '').strip()\n",
    "\n",
    "    # Extract candidate's name and party\n",
    "    name_party_div = candidate_div.find('div', class_='nme-prty')\n",
    "    candidate_name = name_party_div.find('h5').text.strip() if name_party_div.find('h5') else ''\n",
    "    party_name = name_party_div.find('h6').text.strip() if name_party_div.find('h6') else ''\n",
    "\n",
    "    # Append candidate details to the list\n",
    "    candidates.append({\n",
    "        'state': state,\n",
    "        'pc_name': pc_name,\n",
    "        'candidate': candidate_name,\n",
    "        'party': party_name,\n",
    "        'status': status,\n",
    "        'total_votes': total_votes,\n",
    "        'margin': margin,\n",
    "        'image_url': img_url\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of candidates\n",
    "df = pd.DataFrame(candidates)\n",
    "\n",
    "# Convert total_votes to numeric, handling errors by converting to NaN and then to 0\n",
    "df['total_votes'] = pd.to_numeric(df['total_votes'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Calculate the sum of total_votes and add it as a new column\n",
    "df['sum_totalvotes'] = df['total_votes'].sum()\n",
    "\n",
    "# Generate a safe file name by replacing spaces with underscores and converting to lowercase\n",
    "file_name = f\"CCR_{state}_{pc_name.replace(' ', '_')}.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Data extracted and saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225acce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf927994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
